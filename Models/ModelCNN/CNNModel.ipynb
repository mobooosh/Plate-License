{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df495c89-efc9-4292-a2ac-6309bfdc804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9986cf-51b0-4f05-ba2f-8c4285ea6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6673e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tf.config.list_physical_devices('GPU')[0]\n",
    "tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52671c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"mergedData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "743c4fe6-4af3-4641-ac38-95f5baa825cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.listdir(train_dir)\n",
    "lbl = []\n",
    "for e in path:\n",
    "    lbl.append(e.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85bb8d27-a6ba-45b8-a09d-97cfe8dbe141",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set(char for label in lbl for char in label)\n",
    "characters = sorted(list(characters))\n",
    "char_to_num = layers.StringLookup(\n",
    "    vocabulary=list(characters), mask_token=None\n",
    ")\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77e9a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = char_to_num.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeabe7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "tokenized_lbls = []\n",
    "for i in path:\n",
    "    image_paths.append(os.path.join(train_dir, i))\n",
    "    temp = []\n",
    "    for char in i.split('_')[0]:\n",
    "        temp.append(int(char_to_num(char)))\n",
    "    tokenized_lbls.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915a11b1-ba08-48bc-80ff-e896476af8f5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fd1b26b-a993-424a-8544-f426e5257b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  8672\n",
      "train size:  7804\n"
     ]
    }
   ],
   "source": [
    "tf.config.optimizer.set_jit(True)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "desired_height = 65\n",
    "desired_width = 256\n",
    "\n",
    "def normalization(image):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = normalization(image)    \n",
    "    image = tf.image.resize(image, [desired_height, desired_width])\n",
    "    return image\n",
    "\n",
    "# def data_augmentation(image):\n",
    "#     image = tf.image.adjust_contrast(image, 0.4)\n",
    "#     image = tf.image.adjust_brightness(image, 0.3)\n",
    "#     image = tf.image.adjust_saturation(image, 0.3)\n",
    "#     return image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_image_label(path, label):\n",
    "    image = load_image(path)\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    # image = data_augmentation(image)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label\n",
    "    \n",
    "SHUFFLE_BUFFER_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, tokenized_lbls))\n",
    "\n",
    "\n",
    "validation_split = 0.1\n",
    "DATASET_SIZE = len(list(dataset))\n",
    "print(\"Dataset size: \", DATASET_SIZE)\n",
    "train_size = int((1-validation_split) * DATASET_SIZE)\n",
    "print(\"train size: \", train_size)\n",
    "train_dataset = dataset.take(train_size)\n",
    "validation_dataset = dataset.skip(train_size)\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "validation_dataset = validation_dataset.map(load_image_label, num_parallel_calls=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE, num_parallel_calls=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77fda4-8cfc-44da-8db0-bdff0b702fee",
   "metadata": {},
   "source": [
    "### Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c48d67d-c5cb-46fe-bd83-9ed0c5526981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import GlobalAveragePooling2D, MaxPool1D, Conv1D, Reshape, Input, Dense, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.losses import Loss\n",
    "from keras.optimizers import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "665f69bf-ae5b-47ec-af90-a82a6d38ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = (width // 16, (height // 16) * 256)\n",
    "nclasses = len(char_to_num.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90984a0c-9ac8-4266-a2b1-f570876bb6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 256, 65, 3)]      0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 256, 65, 32)       896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 128, 32, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 128, 32, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 64, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 64, 16, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 32, 8, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 32, 8, 256)        295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 16, 4, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " reshape_2 (Reshape)         (None, 16, 1024)          0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16, 128)           131200    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 16, 64)            24640     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 8, 64)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8, 64)             0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 8, 29)             1885      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 546141 (2.08 MB)\n",
      "Trainable params: 546141 (2.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(width, height, 3))\n",
    "conv2d_1 = Conv2D(32,(3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "maxpool_1 = MaxPooling2D((2, 2))(conv2d_1)\n",
    "\n",
    "conv2d_2 = Conv2D(64,(3, 3), activation=\"relu\", padding=\"same\")(maxpool_1)\n",
    "maxpool_2 = MaxPooling2D((2, 2))(conv2d_2)\n",
    "\n",
    "conv2d_3 = Conv2D(128,(3, 3), activation=\"relu\", padding=\"same\")(maxpool_2)\n",
    "maxpool_3 = MaxPooling2D((2, 2))(conv2d_3)\n",
    "\n",
    "conv2d_4 = Conv2D(256,(3, 3), activation=\"relu\", padding=\"same\")(maxpool_3)\n",
    "maxpool_4 = MaxPooling2D((2, 2))(conv2d_4)\n",
    "\n",
    "reshape = Reshape(target_shape=new_shape)(maxpool_4)\n",
    "dense_1 = Dense(128, activation=\"relu\")(reshape)\n",
    "dropout1 = Dropout(0.2)(dense_1)\n",
    "\n",
    "conv1d = Conv1D(64, 3, activation=\"relu\", padding=\"same\")(dropout1)\n",
    "\n",
    "maxpool_5 = MaxPool1D(2)(conv1d)\n",
    "\n",
    "dropout2 = Dropout(0.5)(maxpool_5)\n",
    "\n",
    "output_layer = Dense(nclasses, activation=\"softmax\")(dropout2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e984a03-057d-4747-a270-13f62263e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_obj = keras.losses.SparseCategoricalCrossentropy()\n",
    "accuracy = keras.metrics.Accuracy()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "early_stopping_patience = 15\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7,\n",
    "                              patience=3, min_lr=0.0001)\n",
    "\n",
    "callbacks = [keras.callbacks.TensorBoard(), early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1efbdcb5-fe00-4f5d-a8ff-b06347839095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719576282.325001    4011 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1719576288.310007    4010 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 24s 46ms/step - loss: 2.4647 - accuracy: 0.2173 - val_loss: 1.4462 - val_accuracy: 0.5592 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "244/244 [==============================] - ETA: 0s - loss: 1.2215 - accuracy: 0.6281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1719576316.387808    4008 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 18s 74ms/step - loss: 1.2215 - accuracy: 0.6281 - val_loss: 0.6363 - val_accuracy: 0.8406 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.7558 - accuracy: 0.7852 - val_loss: 0.3872 - val_accuracy: 0.9018 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.5614 - accuracy: 0.8445 - val_loss: 0.3209 - val_accuracy: 0.9251 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.4606 - accuracy: 0.8751 - val_loss: 0.2913 - val_accuracy: 0.9352 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.3919 - accuracy: 0.8959 - val_loss: 0.2548 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.3409 - accuracy: 0.9073 - val_loss: 0.2349 - val_accuracy: 0.9417 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.3109 - accuracy: 0.9168 - val_loss: 0.2321 - val_accuracy: 0.9435 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "244/244 [==============================] - 7s 27ms/step - loss: 0.2758 - accuracy: 0.9250 - val_loss: 0.2093 - val_accuracy: 0.9492 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.2488 - accuracy: 0.9308 - val_loss: 0.2076 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.2393 - accuracy: 0.9346 - val_loss: 0.2111 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.2155 - accuracy: 0.9407 - val_loss: 0.2181 - val_accuracy: 0.9505 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1923 - accuracy: 0.9461 - val_loss: 0.2034 - val_accuracy: 0.9519 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1823 - accuracy: 0.9488 - val_loss: 0.2209 - val_accuracy: 0.9489 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1798 - accuracy: 0.9496 - val_loss: 0.2513 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1647 - accuracy: 0.9542 - val_loss: 0.2279 - val_accuracy: 0.9545 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1345 - accuracy: 0.9609 - val_loss: 0.2312 - val_accuracy: 0.9564 - lr: 7.0000e-04\n",
      "Epoch 18/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1258 - accuracy: 0.9636 - val_loss: 0.2372 - val_accuracy: 0.9575 - lr: 7.0000e-04\n",
      "Epoch 19/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.1202 - accuracy: 0.9655 - val_loss: 0.2426 - val_accuracy: 0.9575 - lr: 7.0000e-04\n",
      "Epoch 20/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0998 - accuracy: 0.9710 - val_loss: 0.2456 - val_accuracy: 0.9556 - lr: 4.9000e-04\n",
      "Epoch 21/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0951 - accuracy: 0.9725 - val_loss: 0.2462 - val_accuracy: 0.9562 - lr: 4.9000e-04\n",
      "Epoch 22/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0919 - accuracy: 0.9726 - val_loss: 0.2374 - val_accuracy: 0.9555 - lr: 4.9000e-04\n",
      "Epoch 23/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0796 - accuracy: 0.9761 - val_loss: 0.2401 - val_accuracy: 0.9584 - lr: 3.4300e-04\n",
      "Epoch 24/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0783 - accuracy: 0.9768 - val_loss: 0.2582 - val_accuracy: 0.9594 - lr: 3.4300e-04\n",
      "Epoch 25/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0727 - accuracy: 0.9781 - val_loss: 0.2628 - val_accuracy: 0.9582 - lr: 3.4300e-04\n",
      "Epoch 26/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0657 - accuracy: 0.9799 - val_loss: 0.2541 - val_accuracy: 0.9585 - lr: 2.4010e-04\n",
      "Epoch 27/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0609 - accuracy: 0.9815 - val_loss: 0.2672 - val_accuracy: 0.9585 - lr: 2.4010e-04\n",
      "Epoch 28/50\n",
      "244/244 [==============================] - 6s 26ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.2810 - val_accuracy: 0.9575 - lr: 2.4010e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fa84c48fe90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55443271-f00e-47e7-a8b5-59cf88787286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ModelCNN.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ModelCNN.tf/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('ModelCNN.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbc2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = tf.keras.models.load_model('./ModelCNN.tf/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
